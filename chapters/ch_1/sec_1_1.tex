The motivation behind the development of the original fast multipole method (\gls{FMM}), was the calculation of $N$-body problems,

\begin{flalign}
    \label{eq:n_body:sec:1_1}
    \phi_j = \sum_{i=1}^N K(x_i, x_j)q_i
\end{flalign}

Consider electrostatics, or gravitation, where $q_i$ is a point charge or mass, and $K(x,y) = \frac{1}{4\pi|x-y|}$ is the Laplace kernel. Similar sums appear in the discretised form of boundary integral equation (BIE) formulations for elliptic partial differential equations (PDEs), which are the example that motivates our research. Generically, an integral equation formulation can be written as,

\begin{flalign}
    \label{eq:generic_int_equation:sec:1_1}
    a(x)u(x) + b(x) \int_\Omega K(x, y)c(y)u(y)dy = f(x), \> \> x \in \Omega \subset \mathbb{R}^d
\end{flalign}

where the dimension $d = 2$ or $3$. The functions $a(x)$, $b(x)$ and $c(y)$ are given and linked to the parameters of a problem, $K(x,y)$ is some known kernel function and $f(x)$ is a known right hand side, $K(x,y)$ is associated with the PDE - either its Green's function, or the derivative. This is a very general formula, and includes common problems such as the Laplace equation, Lippman-Schwinger equation and the Helmholtz equation in the low frequency case. Upon discretisation using some appropriate method, for example the Nystr√∂m or Galerkin methods, we obtain a linear system of the form,

\begin{flalign}
    \label{eq:linear_system:sec:1_1}
    \mathsf{K} u = f
\end{flalign}

The defining feature of this linear system is that $\mathsf{K}$ is \textit{dense}, with non-zero off-diagonal elements. Such problems are \textit{globally data dependent}, in the sense that the calculation at each element in the discrete system depends on all other elements.

This density made numerical methods based on boundary integral equations prohibitively expensive prior to the discovery of so called `fast algorithms', of which the FMM is the prototypical example. The naive computational complexity of storing a dense matrix, or calculating its matrix vector product is $O(N^2)$, and the complexity of finding its inverse is $O(N^3)$, where $N$ is the number unknowns. This cost should have made the construction of numerical software based on boundary integral formulations moot, however the FMM demonstrated that the rapid decay behaviour exhibited by certain classes of kernel function can be exploited to reduce the asymptotic cost of handling dense matrices in formulations that result from them. 

In the best case the matrix vector product described by (\ref{eq:n_body:sec:1_1}) and (\ref{eq:linear_system:sec:1_1}) can be computed in just $O(N)$ \gls{FLOPS} and stored with $O(N)$ memory. Given the wide applicability of boundary integral equations to natural sciences, from acoustics \cite{wolf2011aeroacoustic,hao2015efficient} and electrostatics \cite{wang2021high} to electromagnetics \cite{darve2004fast} fluid dynamics \cite{rahimian2010petascale} and earth science \cite{chaillat2008multi}. The FMM can be seen to have dramatically brought within reach large scale simulations of a wide class of scientific and engineering problems. 

Furthermore, the FMM can also be applied to volume integral equations \cite{malhotra2015pvfmm}. Indeed, as (\ref{eq:n_body:sec:1_1}) shares its form with the kernel summations often found in statistical applications, the FMM has found uses in and computational statistics \cite{ambikasaran2013large}, machine learning \cite{lee2012distributed} and Kalman filtering \cite{li2014kalman}.

Despite their different origins and formulations, these example applications are united by their global data dependency. Resolving this is the key challenge in developing software for fast algorithms. The rapid decay behaviour between physically distant interactions required by these algorithms is often referred to as `low rank', in which cases a compressed representation may be sought

...Figure illustrating low-rank assumption.
 
...FMM logic. It relies on a recursive data structure to hierarchically partition a domain of interest. In two dimensions, we use a quadtree (FIGURE FOR QUADTREE), and in three dimensions we use an octree (FIGURE FOR OCTREE). Denoting the set of points contained within a node of a tree as a `cluster', the basic logic of the FMM, regardless of its flavour (see section \ref{sec:1_2}), involves a hierarchical recursion through the tree, and approximating interactions between distant clusters where a low-rank assumption can be applied. This is the how the FMM, and other fast-algorithms, can 

% Yokota, Ibeid, Keyes (2016)

% - Applications of FMM can be broadly categorised as elliptic PDEs and kernel summation.

% - Integral forms of elliptic PDEs for which FMM applies
%     - boundary integrals for homogenous problems
%     - discrete volume integrals
%     - continuous volume integrals

% Continuous volume integrals:
% Schrodinger 106
% Stokes 77

% - Common feature of all applications is that they are global problems whre the calculation at every location depends on values everywhere else.

% - Dense matrices in BIEs <=> all to all interaction in N body problems, and kernel summations with global support -> all manifestations of same global problem.

% - Uniform resolution use FFT, introduce FFT as first 'fast algorithm', however has unfavourable communication cost.
% - For non-uniform global problems also have multigrid methods as an alternative, also O(N) cost for elliptic/hyperbolic PDE problems. Gholami, Malhotra, Sundar, Biros (2016) - multigrid decent.

% - Ambikasaran \& Darve summarise differences between different algebraic methods.
%     - H, H2, HSS, HBS, HODLR.

% - Purely algebraic methods
%     - precompute and store entire hierarchical matrix.
%     - more storage, more data movement - both vertically and horizontally in memory hierarchy.

% - When the cost of data movement increases faster than arithmetic operations on future architectures, the methods that compute more to store/move less will become advantageous (computationally) - tradeoff results in KIFMM as choice - semi-analytical.

% - algebraic variants commonly argued to be superior as they operate directly on the matrix without th eneed to pass geometric information
%     - not convincing on their own.
%         - major libraries (PETSc) offer interfaces to insert a matrix free preconditioner as a function, and passing geometric info is something users are willing to do if it increases performance.
%     - Always just comes down to the flops vs bytes trade-off
%     - need a decent reference or description of where architecture technology is heading in order to justify our choice of FMM.

% - Note, analytical FMM have very high arithmetic intensity (flop/byte).
%     - not brute force methods doing wasteful calculations, only doing useful flops. Very different from achieving high arithmetic intensity on dense mat-mat mults or LU decompositions.
%     - Bonsai - an analytical treecode.

% - Fast translation operators crucial - take up a lot of time of the FMM, whatever its implementation.
%     - analytical options for fast translation operators.
%         - Rotation of spherical harmonics 92
%         - Block FFT 36
%         - Planewaves 50

%     - Accelerating M2L step
%         - level-skip M2L method 91
%         - 8,4,2 box method 93
%         - methods that use dual tree traversal alongside multipole acceptance criterion to construct optimal interaction lists 34

%     - Variable expansion order
%         - VFMM 85
%         - Guassian VFMM 20
%         - optimal parameter FMM 28
%     - intuition = boxes further away can afford to be of lower expansion order without loss of accuracy.

%     - Can store translations as matrices - typical optimisation
%         - matrix compression techniques - randomized techniques too.
%         - matrix techniques allow one to take advantage of BLAS
%             - maximises cache utilisation 39 (And US in PyExaFMM)
%         - Combination of techniques like Chebychev with SVD 38
%             - essentially systematic way of doing something like variable expansion order.
% - FMM is a method that has the analytical form to generate small (low-rank) off-diagonal matrices without needing to rely on a numerical approximation method.

% - making better use of translational invariance and rotational symmetry of the interaction list one can reduce the amount of storage further - 30, 32, 89

% % It remains an outstanding challenging in research software to optimally map fast algorithms including the FMM to modern distributed computing systems. We address some of these challenges in this thesis, including the implementation of distributed octrees data structures (section (\ref{sec:2_3})), efficient low-rank compression techniques (section (\ref{sec:3_2})) and designing for ergonomic software that can be deployed by anyone, anywhere (section \ref{sec:2_3}).
