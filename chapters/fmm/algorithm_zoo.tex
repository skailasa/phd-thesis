
\section{Algorithm Zoo}\label{chpt:fmm:sec:algorithm_zoo}

Having described the key intuition behind the \acrshort{fmm} for oscillatory and non-oscillatory kernels, as well as our variant of interest the \acrshort{kifmm} of Ying and co-workers. We use this section to describe a few of the vast numbers of variant approaches to compute the \acrshort{fmm}, and unify the literature on \acrshort{fmm} with that of the closely related \textit{hierarchical matrices}, or $\H$ matrices for short.

The \acrshort{fmm} and related methods principally vary with respect to their admissability criterion, method of field approximation, and underlying hierarchical data structure used.

Often \acrshortpl{fmm} and related methods are grouped roughly into three categories

\textbf{Analytic}, where kernel dependent expansions are used to approximate the fields. Original method, extended since then to a range of PDE kernels, including oscillatory problems described by time harmonic maxwell and helmholtz equations. For example originally, a multipole expansion was used. In 2D these take the form of simple coefficients, in 3D for Laplace already have to deal with spherical harmonic basis.

\textbf{Semi-Analytic}, examples include the kiFMM and the bbFMM, here only kernel evaluations are used however analytical properties are required in the construction of the fictitious surfaces on which the methods rely. examples include the kiFMM of \cite{Ying:2004:JCP} and also the black box FMM \cite{fong2009black}.

\textbf{Algebraic}, purely rely on kernel evaluation, Martinsson and Rokhlin 2011 \cite{martinsson2007accelerated}

- Analytical FMMs
- different expansion representations, and their impact on complexity, table from yokota paper,
- comment on complexity vs real implementation (special functions computation, for some kernels there are simplifying approaches e.g. Gumerov real Laplace expansions)

- Comment on lack of unified comparison in the literature

The line between `algebraic' and `semi-analytic' is fuzzy in practice, as the nature of the computations have an extremely close correspondence, and in the example of the kiFMM of \cite{Ying:2004:JCP} equivalent up to a choice of discretisation to the purely `algebraic' $\Htwo$ matrix scheme.

When it comes to practical performance there is a gap in the literature in terms of a direct comparison between these rough approaches. Many of them achieve optimal asymptotic complexities, however practical performance depends principally on components that appear as constants in complexity estimates - related to memory accesses, and optimal vectorisation and parallelisation where possible.

Indeed, the \acrshort{fmm} can be seen to be a special case of the more general hierarchical matrices, or $\H$ matrices for short.

- Generally considered that low-order analytical and high-order algebraic approaches, for performance however this is not actually known.

- analytical requires evaluation of special functions, what does this look like on modern architectures? Surely this is not a preferred operation, and will not be going in to the future.

Common $\H$ matrix formats are summarised in table [Ambikasaran table], indeed we see that the FMM is actually of class $\Htwo$. Though often written about in different contexts, and by different geographically disparate communities, algebraic variants of the the \acrshort{fmm} can be seen to be equivalent to methods for $\Htwo$ matrices, the principal difference being that algebraic \glspl{fmm} are commonly defined using quad/octrees whereas $\Htwo$ matrices rely on the more generic `cluster tree' approach that works directly with matrix entries.

- How are analytical expansions defined, 2D Laplace example, note and references on 3D laplace example.
    - private note on how these derivations are found.

- Note on admissibility, how it defines a broad class of FMM matrices, table of related matrix types with different rank structure and admissability criterion

- HSS, HBS, $\H$, $\Htwo$ exactly where does the FMM fit in.

- What is the expected complexity of matrix vector product, how do they differ (nested vs non-nested bases).

- How are off diagonals approximated? Linear algebra. e.g. SVD/ACA/CUR decompositions vs analytical expansions.

- Relative costs of computing these, precomputation is expensive in general compared to FMM which uses analytical expansions and minimal precomputation costs.

- Alternative to geometry captured by oct/quadtree. ORB could also be used for the FMM.

- But rely on cluster tree and cluster block trees over the matrix indices.

This is achieved with a hierarchical discretisation of the problem domain, often a \textit{quadtree} in two dimensions and correspondingly an \textit{octree} in three dimensions.

- trees define admissability from geometry for FMM, note on alternative approaches such as ORB.

- can control interaction list in different ways by using control parameter in ORB.

- Control of the interaction list is an optimisation used in stencil based approaches, more recent efforts like the Yesypenko paper, older approaches like Gumerov and the 8,4,2 method mentioned in the Yokota summary paper.

- These data structures are generated by creating a bounding box that covers the source and target particles, which without loss of generality may correspond to the same set. This box is then recursively sub-divided into \textit{child boxes} of equal size.

- There is relatively little work directly contrasting the relative merits of different approaches for constructing \acrshortpl{fmm}. Yokota et. al \cite{yokota2015fast} provide some analysis, attempting to bound the vast literature on \acrshort{fmm} and related methods, however stop short of rigorous benchmarks. Indeed, direct software benchmarks between different groups and approaches can be flawed for numerous reasons, principally whether or not a given implementation was optimised for optimal hardware use or simply for demonstrative purposes. Furthermore, Yokota et. al only compare their analytical implementation of the \acrshort{fmm} for Laplace kernels in 3D with an implementation for HSS matrices, which though of the same asymptotic complexity, have completely different scaling properties in 3D.

- A general rule of thumb has so far been that algebraic methods perform better at high order, meanwhile analytical methods are more suitable for low order. It's understandable to see where this point of view comes from. The translation operators for analytical \acrshortpl{fmm} take the form of very short sums, potentially involving special functions. The practical evaluation of which though highly optimised, are inherently expensive in terms of \acrshortpl{flop} for high order evaluations. On the other hand, kernel independent approaches rely only on the evaluation of matrix blocks that are constructed via kernel evaluation, and therefore are easy to express as \acrshort{blas} operations.

- As a point of direct comparison, we present the scaling on a single node of computing the Laplace problem in 3D on a range of modern softwares. We compute the problem on the surface of a sphere, taking increasingly fine discretisations of its surface, a sphere is chosen as a range of modern \acrshort{fmm} and $\Htwo$ matrix software is optimised for \acrfull{bem} applications

Alternative $N$-body approaches, there has been limited work except a landmark study \cite{gholami2016fft}, again the asmpyotic costs of these competing approaches is important

- Asymptotic costs of competing approaches include $\bigO{N \log{N}}$ for the \acrshort{fft} and $\bigO{N}$ for multigrid

- The FFT has been shown to have $\bigO{P^{1/d}}$ communication complexity, with $\bigO(\log{P})$ for multigrid. Recently the \acrshort{fmm} has also been shown to have $\bigO{\log{P}}$ communication complexity, and therefore the trade-offs between different approaches are significantly harder to contrast.

- FFT is generally preferred for problems with uniform resolution, multiscale features are somewhat better handled by the FMM and multigrid in theory. However, interpolation of non-uniform features can be handled efficiently with effective \acrshort{simd} and caching optimisations.

- But the most important costs are related to data handling, and unique again to a specific implementation.

\begin{table}[ht]
    \centering
    \caption{Comparison of Expansion Types, adapted from \cite{Yokota2013} and expanded with more recent variants and estimates.}
    \begin{tabular}{lcc} % lcc means left-align the first column, center-align the other two
    \toprule
    \textbf{Approximation Scheme (+ M2L Scheme)} & \textbf{Storage} & \textbf{Naive Arithmetic} \\
    \midrule
    Cartesian Taylor & $\bigO{P^3}$ & $\bigO{P^6}$ \\
    Cartesian Chebyshev (+ Direct Compression) & $\bigO{P^3}$ & $\bigO{P^6}$ \\
    Spherical Harmonics & $\bigO{P^2}$ & $\bigO{P^4}$ \\
    Spherical Harmonics (+ `point and shoot') & $\bigO{P^2}$ & $\bigO{P^3}$ \\
    Spherical Harmonics (+ FFT) & $\bigO{P^2}$ & $\bigO{P^2 \log{P}}$ \\
    Planewave & $\bigO{P^2}$ & $\bigO{P^3}$ \\
    Equivalent Charges & $\bigO{P^2}$ & $\bigO{P^4}$ \\
    Equivalent Charges (+ FFT) & $\bigO{P^3}$ & $\bigO{P^3 \log{P}}$ \\
    Equivalent Charges (+ Direct Compression) & $\bigO{P^2}$ & $\bigO{k^2 \cdot P^2}$ \\
    \bottomrule
\end{tabular}
\end{table}


