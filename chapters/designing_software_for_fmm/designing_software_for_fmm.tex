\chapter{Software Design}\label{chpt:software_design}
\thispagestyle{chaptertitle} % Force the fancy style on this page


\section{Data Oriented Design with Rust Traits}

- Motivation, and review, DOD book.

- How do traits enable data oriented design.

- Overview of the design of the software.

- Diagram for principal traits and how they link together in the final software.

- Why is this good for the future? Well, it leaves open extension to other approaches for any individual subcomponent.

- An example of this is the genericity over data type, kernel implementation, and field translation method, with a space for the kind of tree data structure.

- Exactly how is decoupling achieved with trait interfaces?
    - decoupling of implementation from abstraction.

\section{FMM Software As A Framework}

- Want to encourage as much code re-use as possible.

- The re-implementation of critical subcomponents should be avoided. A step towards this is the development low-level C interfaces which enable the construction of higher level interfaces in compatible languages.

- We've made a start to this with a low-level interface to the principal API of the FMM software.

- We also want to be able to deploy on as wide a range of target hardware as possible, and leave open extension to future systems, enabled by design, referencing diagram.

- High level diagram of how software components fit together


- Code generation for multiple targets enabled by Rust's llvm based compiler.

- C ABI as a compatiblity layer to other projects, success with this in developing Python wrappers and integration with NGBEM

- Flexible backends enabled by RLST package for BLAS and Lapack.

\section{Case Study: A Trait Based M2L}

- How do metadata computations work for a configurable M2L implementation? What does the high-level framework expect of an M2L implementation?

- What does this look like in practice? Exactly what traits are there, how can re-implement them for an alternative M2L implementation?


In principal, how could one also implement a new FMM, a new tree or a new operator for e.g. GPU?

This is incredibly compelling for an FMM software, as it can serve as a testbed for extension and algorithmic experimentation as well as comparison. E.g. we could attempt to use our framework to directly compare analytical and kiFMM methods, re-using the same kernel/lapack/blas backends, tree data structure, the only difference would be the translation operator implementations allowing for a fair comparison.

\section{High Performance Trees}

- Exactly how are Morton encodings done, and what are the drawbacks and alternatives. Hilbert encodings, ORB. How much difference do any of these things make?

- Tree Construction approach and algorithms
    - Morton encoding via lookup tables
    - neighbour finding
    - interaction list construction (fast)

- What did we end up doing, and what is the justification for these being good enough.
    - weakly adaptive vs fully adaptive FMM.
    - why?


Important implementation details
    - construction of interaction lists, neighbour finding.
    - construction of Morton encodings.
    - rapid data access, lookup tables/index pointers
    - trade-offs of approach in shared and distributed memory
        - e.g. adaptive vs weakly adaptive trees.
        - problems with load balancing approach etc

- How am I storing key data? I'm not using a pure Z order in the data layout, I'm storing by level in Morton order for ease of lookup of contiguous sibling data

- How are multi/single node trees designed?

- basically, have a very shallow struct, with trait interfaces that define the trees/fmm trees. This means that the actual tree is incredibly abstract, and flexible. Being able to query it like a single node tree means that kernel code is largely unchanged for operators.


\section{FMM Metadata}

- Arguably the most important part of setting up the calculation to be fast is calculating metadata effectively, i.e. need to move as much of the work away from the runtime as possible.

- Most important pieces here are figuring out how the interaction lists correspond to runtime data structures in M2L.




