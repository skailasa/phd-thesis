/*! \page sparse Sparse Direct Solver


+ \subpage algorithm "Algorithm Overview"
+ \subpage sparse_example_usage "Example Usage"



This section gives an overview on the basic usage of the sparse
solvers in STRUMPACK. Many STRUMPACK options can be set from the
command line. Running with \--help or -h, will give you a list of
supported run-time options.

An example Makefile is available in the examples/ directory. This is a
simple manual Makefile, with certain variables set during the
__CMake__ configure phase, see \link installation Installation and
Requirements\endlink.

STRUMPACK is written in C++, and offers a simple C++ interface. See
\link C_Interface C Interface \endlink if you prefer a C
interface. The STRUMPACK sparse solver has three different solver
classes, all interaction happens through objects of these classes:

- \link strumpack::StrumpackSparseSolver
StrumpackSparseSolver<scalar,integer=int>\endlink This class
represents the sparse solver for a single computational node,
optionally using OpenMP parallelism. Use this if you are running the
code sequentially, on a (multicore) laptop or desktop or on a single
node of a larger cluster. This class is defined in
StrumpackSparseSolver.hpp, so include this header if you intend to use
it.

<!---
- \link strumpack::StrumpackSparseSolverMPI
StrumpackSparseSolverMPI<scalar,integer=int>\endlink This solver has
(mostly) the same interface as \link strumpack::StrumpackSparseSolver
StrumpackSparseSolver<scalar,integer=int>\endlink but the numerical
factorization and multifrontal solve phases run in parallel using MPI
and ScaLAPACK. However, the inputs (sparse matrix, right-hand side
vector) need to be available completely on every MPI process. The
reordering phase uses Metis or Scotch (not ParMetis or PTScotch) and
the symbolic factorization is threaded, but not distributed. The
(multifrontal) solve is done in parallel, but the right-hand side
vectors need to be available completely on every processor. Make sure
to call MPI_Init[_thread] before instantiating an object of this class
and include the header file StrumpackSparseSolverMPI.hpp. We do not
recommend this solver, instead, use \link
strumpack::StrumpackSparseSolverMPIDist
StrumpackSparseSolverMPIDist\endlink whenever possible.
-->


- \link strumpack::StrumpackSparseSolverMPIDist
StrumpackSparseSolverMPIDist<scalar,integer=int>\endlink This solver
is fully distributed. The numerical factorization and solve as well as
the symbolic factorization are distributed. The input is now a
block-row distributed sparse matrix and a correspondingly distributed
right-hand side. For matrix reordering, ParMetis or PT-Scotch are
used. Include the header file StrumpackSparseSolverMPIDist.hpp and
call MPI_Init[_thread].

The three solver classes \link StrumpackSparseSolver.hpp
StrumpackSparseSolver\endlink, \link StrumpackSparseSolverMPI.hpp
StrumpackSparseSolverMPI\endlink and \link
StrumpackSparseSolverMPIDist.hpp StrumpackSparseSolverMPIDist\endlink
depend on two template parameters <scalar,integer>: the type of a
scalar and an integer type. The scalar type can be float, double,
std::complex<float> or std::complex<double>. It is recommended to
first try to simply use the default integer=int type, unless you run
into 32 bit integer overflow problems. In that case one can switch to
for instance int64_t (a signed integer type).

____


*/


