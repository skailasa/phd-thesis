\thispagestyle{plain}

\begin{center}
    \textbf{Abstract}
\end{center}

- The past three decades have seen the emergence of so called `fast algorithms' that are able to rapidly apply and invert the operator matrices arising from boundary integral forms of elliptic PDEs. Such equations are common in acoustic and electromagnetic scattering, with applications from X to Y.
- However, a `data-sparse' but dense system matrix arises in other problems too, for example in dense covariance matrices for Kalman filtering, and other compuational statistics problems.
- The unification of software for the forward and inverse application of these operators in a single set of open-source libraries optimised for distributed computing environments is severely lacking, and is the central concern of this thesis. Where implementations exist they are fragmented, with a focus on a specific algorithm or problem area, with portions of code parallelised and compatible with distributed computing systems, with other portions being restricted to a single-node. Developing high-performance implementations of fast algorithms is challenging due to highly-technical nature of their underlying mathematics, making it difficult to differentiate between numerical and logical errors when debugging. This is further complicated by the diversity of software and hardware environments in which research code is expected to run - from desktop workstations to the latest supercomputing clusters. 
- In this subsidiary thesis, we present current work on implementing scalable software for the fast forward application of these integral operators, as well as our investigations into the optimal software engineering techniques for their implementation.
- We present our work in the context of ongoing work to implement a unified framework for the rapid forward and inverse application of fast algorithms to the dense system matrices that arise in boundary integral formulations for wave scattering problems.
- The first part of this thesis introduces the analytic Fast multipole method, and its semi-analytic and algebraic variants and their trade-offs.
- We proceed to a discussion on of an attempted Python implementation of the semi-analytic KIFMM, and its shortfalls and subsequently introduce Rust - a relatively new, but emerging language for scientific and high-performance computing.
- We present progress on a Rust based implementation of the fast multipole method, and discuss numerical results and remaining challenges as we hope to scale to exascale particle simulations.
- We conclude with a look to the future, and sketch a plan for a unified forward/backward solver framework.

% Integral equation methods are a powerful technique for the solution of the boundary value problems that arise from electromagnetic and acoustic scattering. This because they reduce problems defined over unbounded domains into ones defined by a boundary integral. The principle drawback of such methods is the dense linear matrices that must be either applied or inverted in the resulting linear system upon discretisation, depending on whether one is solving the forward or inverse problem. The past three decades have seen the development of so called `fast algorithms' that allow for an accelerated forward and inverse application of these operator matrices, the initial innovation being the fast multipole method (FMM), which in the optimal case accelerates the forward application to $\text{O}(N)$. More recently so called `fast direct solvers' have emerged to calculate the operator inverse, again with a best case complexity of $\text{O}(N)$. The unification of software for the forward and inverse application of these operators in a single set of open-source libraries optimised for distributed computing environments is severely lacking, and is the central concern of this thesis. Where implementations exist they are fragmented, with a focus on a specific algorithm or problem area, with portions of code parallelised and compatible with distributed computing systems, with other portions being restricted to a single-node. Developing high-performance implementations of fast algorithms is challenging due to highly-technical nature of their underlying mathematics, making it difficult to differentiate between numerical and logical errors when debugging. This is further complicated by the diversity of software and hardware environments in which research code is expected to run - from desktop workstations to the latest supercomputing clusters. With these challenges in mind we use Rust as the implementation language for our infrastructure. Rust is a young language, designed for low-level systems programming much like C. However, it has a fledgling scientific computing community, with good support for many key features such as MPI support parallel multithreading and containers for numerical data. The most beneficial feature of Rust is its cross-platform toolchain, Cargo, which makes building software painless. In this subsidiary upgrade thesis we introduce both the FMM and fast direct solvers in the context of acoustic and electromagnetic scattering problems, and document the software and mathematical implementation challenges we will face when developing our solver infrastructure and our proposed investigations and solutions. We introduce Rust, its key benefits and open challenges, and demonstrate its viability as a tool for high-performance computational science via Rusty Tree, a cross-platform package for MPI-distributed octrees - a foundational data structure for the FMM and a central library in our solver infrastructure. The key target application of this thesis is the large-scale simulation of high-frequency Maxwell scattering problems, with applications from biophysical simulation to radar and medical imaging, that can be run on any hardware and work with minimum configuration on behalf of the user. Our software infrastructure making the complex implementations of fast algorithms accessible to a wide community of researchers across science and engineering.
