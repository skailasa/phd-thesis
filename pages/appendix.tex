\chapter{Appendix}

\section*{Complexity of RS-S Factorisation}\label{app:a_6:rss_complexity}

This section is adapted from section 3.3.4 of \cite{minden2017recursive}. The RS-S algorithm applies to an arbitrary tree decomposition, i.e. trees may be adaptively refined. To compute complexity bounds they impose some structure to the tree. Specifically, they assume, as standard, a tree with $L = O(\log N)$ levels in $d$ dimensions is given such that each leaf node contains at most a constant number of degrees of freedom independent of $N$. Letting $k_l$ denote the maximum of $\mathcal{S}_i$, i.e the skeleton degrees of of freedom of the tree's nodes on level $l$, and assuming $k_l \leq k_{l+1}$ for all $l$.

Under the above assumptions, and assuming further that a constant number of points is used to discretise the proxy surface $\Gamma$, they show that the cost $T_f$ of construction the RS-S factorisation $F$ using the bottom-up recursive procedure described in chapter \ref{chpt:7:fds}, and the cost $T_s$ of applying $F$ or $F^{-1}$ are given by,


\begin{flalign*}
    T_{f} &= O(N) + \sum_{l-1}^{L-2}O(2^{d(L-l)}k_l^3) \\
    T_s &= O(N) + \sum_{l=1}^{L-2}O(2^{d(L-l)}k_l^2)
\end{flalign*}

The memory requirement is $m_f = O(t_s)$. To show this, let $k_0=1$ without loss of generality. Note that for the DOF set $\mathcal{B}_i$ corresponding to the points in a box at level $l$, we have that $|\mathcal{B}_i| = O(k_{l-1})$, the near field degrees of freedom $|\mathcal{N}_i| = O(k_{l-1})$ and the far-field degrees of freedom within the proxy surface $|\mathcal{Q}_i| = O(k_{l-1})$, since for the leaf nodes the number of degrees of freedom is bounded by a constant, and for non-leaf nodes the degrees of freedom are given by aggregating skeleton degrees of freedom of their children at the previous level.

Because of the proxy compression, the cost of the ID for the skeletonisation of a given box was found to be reduced as we only needed the ID on a box of size  $O(|\mathcal{Q}_i|) \times O(|\mathcal{B}_i|)$ in chapter \ref{chpt:7:fds}. Using the complexity result of the ID from chapter \ref{chpt:7:fds}, we see that the cost of skeletonisation  with respect to the degrees of freedom $B_i$ corresponding to a node at level $l$ is $O(k_l^3)$. Finally, at each level $l$ there are at most $2^{d(L-l)}$ boxes, which gives the stated complexity for $T_f$ above using the fact the $2^{dL} = O(N)$. The authors of \cite{minden2017recursive} note that the complexity for $T_s$ can be similarly derived, noting that all block unit-triangular matrices can be trivially inverted.

We note that the initial tree construction cost will still require an algorithm of $O(N \log N)$ at the least, however the authors note that in practice this is usually a negligible cost in comparison to the factorisation or application themselves.

For kernels that we're interested in, i.e. Green's functions arising from elliptic PDEs at low-moderate frequencies, standard multipole expansions can be used to show that the far field blocks have ranks that depend only weakly on $N$ \cite{minden2017recursive}. In RS-S far-field interaction blocks that have received Schur complement updates to some of their entries from earlier skeletonisation steps, therefore multipole expansions don't strictly apply, but Minden et al indicate that similar rank behaviour still applies which they've confirmed with numerical experiments. Proceeding with this this assumption they observe a stronger complexity bound.

For a fixed tolerance $\epsilon$, we have $k_l = O(l^q)$ for some $q>0$. ie. the skeleton sets grow only as some power of the level index $l$, and $k_{L-2} = O(\log^q N)$, then we obtain

\begin{flalign*}
    T_f = T_s = m_f = O(N)
\end{flalign*}

with differing constants depending on the tolerance $\epsilon$ and dimension $d$.

\section*{Deriving Local Expansion Coefficents from Multipole Expansion in $\mathbb{R}^2$}\label{app:a_1_fmm_algorithm}

Working in the setting in which we derived the multipole expansion in equation (\ref{eq:ch_2:multipole_expansions}),

\begin{flalign}
    \phi(x) = \sum_{j \in I_s} K(x, y)q_j = \log(x-c_s)\hat{q}_0^s + \sum_{p=1}^\infty \frac{1}{(x-c_s)^p}\hat{q}_p^s
    \label{eq:app:multipole_expansion}
\end{flalign}

Deriving the local expansion centered around the origin, where the bounding box of the targets, $\Omega_t$, is well separated from the source box, $\Omega_s$,

\begin{flalign*}
    \phi(x) = \sum_{l=0}^\infty \hat{\phi}^t_l (x-c_t)^l 
\end{flalign*}

from the multipole expansion relies on the following expressions,

\begin{flalign*}
\log((x-c_t)-c_s) &= \log(-c_s(1-\frac{x-c_t}{c_s})) \\
&= \log(-c_s)  - \sum_{l=1}^\infty \frac{1}{l} \left( \frac{x-c_t}{c_s} \right) ^l
\end{flalign*}

and,


\begin{flalign*}
    ((x-c_t)-c_s)^{-p} &= \left( \frac{-1}{c_s} \right)^p \left( \frac{1}{1-\frac{x-c_t}{c_s}} \right)^p \\
    &=  \left( \frac{-1}{c_s} \right)^p \sum_{l=0}^\infty \binom{l+p-1}{p-1} \left( \frac{x-c_t}{c_s} \right)^l
\end{flalign*}

Substituting these expressions into (\ref{eq:app:multipole_expansion}), translated to be centred on $\Omega_t$

\begin{flalign*}
    \phi(x) &= \log((x-c_t)-c_s)\hat{q}^s_0 + \sum_{p=1}^\infty \frac{1}{((x-c_t)-c_s)^p}\hat{q}_p^s \\
     &= \log(-c_s)\hat{q}^s_0 - \left( \sum_{l=1}^\infty \frac{1}{l} \left( \frac{x-c_t}{c_s} \right) ^l\right) \hat{q}^s_0 + \sum_{p=1}^\infty \left( \frac{-1}{c_s} \right)^p \sum_{l=0}^\infty \binom{l+p-1}{p-1} \left( \frac{x-c_t}{c_s} \right)^l \hat{q}^s_p
\end{flalign*}

Identifying the local expansion coefficients as,

\begin{flalign*}
    \hat{\phi}^t_0 = \hat{q}^s_0 \log(-c_s) + \sum_{p=1}^\infty \frac{\hat{q}^s_p}{c_s^p}(-1)^p
\end{flalign*}

and,

\begin{flalign*}
    \hat{\phi}_l^t = \frac{-\hat{q}_0^s}{l c_s^l} + \frac{1}{c_s^l}\sum_{p=1}^\infty \frac{\hat{q}_p^s}{c_s^p} \binom{l+p-1}{p-1} (-1)^p
\end{flalign*}

\section*{HykSort}\label{app:a_3:hyksort}

The parallel splitter selection and HykSort algorithms are provided below. In terms of complexity analysis, we adapt the analysis provided in section 3.4 of \cite{sundar2013hyksort}. The main costs of SampleSort is sorting the splitters and the MPI collectives for data reshuffling. This can lead to a load imbalance and network congestion, represented by a constant $c$ below,

\begin{flalign*}
    T_{ss} = t_c c \frac{N}{p} \log \frac{N}{p} + (t_s + t_w o) \log^2 p + t_w c \frac{N}{p}
\end{flalign*}

Where $t_c$ is the intranode memory slowness (1/RAM bandwidth), $t_s$ interconnect latency, $t_w$ is the interconnect slowness (1/bandwidth), $p$ is the number of MPI tasks in $comm$, and $N$ is the total number of keys in an input array $A$, of length $N$.

The parallel splitter selection algorithm for determining $k$ splitters uses MPI collectives, \texttt{All\_Gather}() and \texttt{All\_Reduce}(). The main cost is in determining the local ranks of the samples using a binary search. The number of iterations $\eta$ depends on the input distribution, the required tolerance $N_\epsilon/N$ and the parameter $\beta$. The expected value of $\eta$ varies as $\log(\epsilon)/\log(\beta)$ and $\beta$ is chosen experimentally to minimise the running time, leading to a complexity of,

\begin{flalign*}
    T_{ps} = \eta t_c \beta k \log \frac{N}{p} + \eta (t_s + t_w \beta k) \log p
\end{flalign*}

HykSort relies on a specialised \texttt{All\_to\_all\_kway}() collective, we defer to the original paper for details. It uses only point to point communications with staged message sends and receives, allowing HykSort to minimise network congestion. It has $\log p / \log k$ stages with $O(N/p)$ data transfer and $k$ messages for each task in every stage. This leads to a complexity of,

\begin{flalign*}
    T_{a2a} = \left( t_s k + t_w \frac{N}{p} \right) \frac{\log p}{\log k}
\end{flalign*}

Finally, HykSort has the same communication pattern as \texttt{All\_to\_all\_kway}(). In addition it relies on the parallel splitter selection algorithm to determine splitters. The main computational cost is the initial local sort, and merging $k$ arrays during each iteration.

\begin{flalign}
    T_{Hk} = t_c \frac{N}{p} \log \frac{N}{p} + \left( t_c \frac{N}{p} + T_{ps}\right) \frac{\log p}{\log k} + T_{a2a}
\end{flalign}

Unlike SampleSort, the complexity of HykSort doesn't involve any $O(p)$ terms. This is the term that can lead to network congestion for higher core counts.

\begin{algorithm}
    \caption{\textbf{Parallel Select}}
    \begin{algorithmic}
        \STATE \textbf{Input:} $A_r$ - array to be sorted (local to each process), $n$ - number of elements in $A_r$, $N$ - total number of elements, $R[0,....,k-1]$ - expected global ranks, $N_\epsilon$ - global rank tolerance, $\beta \in [20, 40]$,

        \STATE \textbf{Output:} $S \subset A$ - global splitters, where $A$ is the global array to be sorted, with approximate global ranks $R[0,...,k-1]$

        \STATE $R^{\text{start}} \gets [0,...,0]$ - Start range of sampling splitters
        \STATE $R^{\text{end}} \gets [n,...,n]$ - End range of sampling splitters
        \STATE $n_s \gets [\beta/p,...,\beta/p]$ - Number of local samples, each splitters
        \STATE $N_{\text{err}} \gets N_\epsilon + 1$

        \WHILE{$N_{\text{err}} > N_\epsilon$}
            \STATE $Q' \gets A_r[\texttt{rand}(n_s, (R^{\text{start}}, R^{\text{end}}))]$
            \STATE $Q \gets$ \texttt{Sort}(\texttt{All\_Gather}($\hat{Q}'$)) 
            \STATE $R^{loc} \gets \texttt{Rank}(Q, A_r)$
            \STATE $R^{glb} \gets \texttt{All\_Reduce}(R^{loc})$
            \STATE $ I[i] \gets \text{argmin}_j | R^{glb} - R[I] | $ 
            \STATE $N_{err} \gets \max |R^{glb} - R{I}|$
            \STATE $R^{\text{start}} \gets R^{loc}[I-1]$
            \STATE $R^{\text{end}}  \gets R^{loc}[I+1]$
            \STATE $n_s \gets \beta \frac{R^{\text{end}}-R^{\text{start}}}{R^{glb}[I+1]-R^{glb}[I-1]}$
        \ENDWHILE
        \STATE \textbf{return }$S \gets Q[I]$
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{\textbf{HykSort}}
    \begin{algorithmic}
        \STATE \textbf{Input:} $A_r$ - array to be sorted (local to each process), $comm$ - MPI communicator, $p$ - number of processes, $p_r$ - rank of current task in $comm$
        \STATE \textbf{Output:} globally sorted array $B$.
        \WHILE{$p > 1$, Iters: $O(\log p/\log k)$} 
            \STATE $N \gets \texttt{MPI\_AllReduce}(|B|, comm)$
            \STATE $s \gets \texttt{ParallelSelect}(B, \{i N/k ; i=1,...,k-1 \})$
            \STATE $d_{i+1} \gets \texttt{Rank}(s_i, B), \> \forall i$
            \STATE $[d_0, d_k] \gets [0, n]$
            \STATE $color \gets \lfloor k p_r/p \rfloor$
            \PARFOR{ $i \in 0,...,k-1$}
                \STATE $p_{recv} \gets m((color-i)\text{mod}k)+(p_r \text{mod}m)$
                \STATE $R_i \gets \texttt{MPI\_Irecv}(p_{recv}, comm)$
            \ENDPARFOR

            \FOR{$i \in 0,...,k-1$}
                \STATE $p_{recv} \gets m((color-i)\text{mod}k)+p_r \text{mod}m$
                \STATE $p_{send} \gets m((color+i)\text{mod}k)+p_r \text{mod}m$
                \STATE $j \gets 2$
                \WHILE{$i > 0$ and $i \text{mod}j = 0$} 
                    \STATE $R_{i-j} \gets \texttt{merge}(R_{i-j}, R_{i-j/2})$
                    \STATE $j \gets 2j$
                \ENDWHILE
                \STATE \texttt{MPI\_WaitRecv}($p_{recv}$)
            \ENDFOR
            \STATE \texttt{MPI\_WaitAll}()
            \STATE $B \gets \texttt{merge}(R_0, R_{k/2})$
            \STATE $comm \gets \texttt{MPI\_Comm\_splitt}($color, comm$)$
            \STATE $p_r \gets \texttt{MPI\_Comm\_rank}(comm)$
        \ENDWHILE
        \STATE \textbf{return } $B$
    \end{algorithmic}
\end{algorithm}

